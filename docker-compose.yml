version: '3.8'

services:
  speechops-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: speechops-api
    ports:
      - "8080:8080"
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
    environment:
      - MODEL_PATH=/app/models/trained.pth
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      - prometheus

  prometheus:
    image: prom/prometheus:latest
    container_name: speechops-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus-alerts.yml:/etc/prometheus/prometheus-alerts.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: speechops-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ADMIN_USER=admin
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    restart: unless-stopped
    depends_on:
      - prometheus

  # MLflow UI (optional)
  mlflow:
    image: python:3.10-slim
    container_name: speechops-mlflow
    ports:
      - "5001:5000"
    volumes:
      - ./mlruns:/mlruns
    working_dir: /mlruns
    command: >
      bash -c "pip install mlflow && mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri /mlruns"
    profiles:
      - full
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:

